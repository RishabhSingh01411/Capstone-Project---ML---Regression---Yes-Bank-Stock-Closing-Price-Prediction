{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "xiyOF9F70UgQ",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RishabhSingh01411/Capstone-Project---ML---Regression---Yes-Bank-Stock-Closing-Price-Prediction/blob/main/Capstone_Project_Regression_Yes_Bank_Stock_Closing_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Submitted By**    - Rishabh Singh"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![yes-bank.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Nu05FGkmZU8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Project Summary: Forecasting Yes Bank's Monthly Stock Closing Prices Amidst Turbulence**\n",
        "\n",
        "This project focuses on predicting the monthly closing price of Yes Bank's stock, a crucial task for investors, stakeholders, and market participants given the bank's prominent position in India's financial sector. Yes Bank has faced significant challenges since 2018, notably the involvement of its co-founder, Rana Kapoor, in a fraud case. This situation, coupled with the bank's issues related to bad loans, has led to regulatory interventions by the Reserve Bank of India, making stock price prediction complex and uncertain.\n",
        "\n",
        "To address this challenge, we leveraged a comprehensive dataset containing monthly stock price data from the bank's inception. This dataset provides essential metrics, including the monthly closing, opening, highest, and lowest stock prices. Our primary objective was to develop predictive models capable of capturing the intricate dynamics and trends in Yes Bank's stock prices, especially in light of the turbulent events and uncertainties affecting the bank's performance.\n",
        "\n",
        "We explored various modeling techniques, focusing on time series models and regression methods, to evaluate their effectiveness in forecasting Yes Bank's stock closing prices. These models were specifically assessed on their ability to incorporate the impact of significant events, such as the fraud case involving Rana Kapoor and regulatory interventions by the Reserve Bank of India.\n",
        "\n",
        "Successfully predicting Yes Bank's stock closing price could offer valuable insights for stakeholders, assisting them in making informed investment decisions. By navigating the complexities and uncertainties surrounding Yes Bank's stock prices, this project aims to enhance understanding of the bank's financial performance and contribute to more effective decision-making in the future."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/RishabhSingh01411/Capstone-Project---ML---Regression---Yes-Bank-Stock-Closing-Price-Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Problem Statement: Predicting Yes Bank's Stock Closing Price**\n",
        "\n",
        "The goal of this project is to create a reliable model that accurately predicts the closing price of Yes Bank's stock. We face challenges like understanding the stock's complex trends, especially after 2018, when its price saw a sudden decline. Multicollinearity, where independent variables are highly correlated, is another challenge. The model needs to handle this to ensure accurate predictions.\n",
        "\n",
        "Additionally, significant events like fraud cases involving the bank's founders and regulatory interventions can impact the stock prices. Our model should capture these effects accurately.\n",
        "\n",
        "We aim for high accuracy in forecasting the stock's closing price, with the K-Nearest Neighbors (KNN) Regression model's 99% accuracy as our benchmark. Achieving this accuracy will provide valuable insights for investors and stakeholders, helping them make informed decisions about Yes Bank's stock.\n",
        "\n",
        "In summary, our project aims to build a predictive model that navigates the complexities of forecasting Yes Bank's stock prices. The goal is to provide stakeholders with a reliable tool for understanding the stock's future performance and supporting their investment decisions."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "# Basic libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Visualisation libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Library to avoid warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ML Libraries\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2xMP7L7Xi5g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/data_YesBank_StockPrices.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "data.head(10)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "rows, columns = data.shape\n",
        "print(f\"Rows: {rows}, Columns: {columns}\")\n"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "\n",
        "data.info()\n"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "total_duplicates = data.duplicated().sum()\n",
        "\n",
        "print(f\"Total number of duplicate rows in the dataset: {total_duplicates}\")\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "missing_values_count = data.isnull().sum()\n",
        "\n",
        "print(\"Missing Values/Null Values Count:\")\n",
        "print(missing_values_count)\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "missing_data = data.isnull()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(missing_data, cmap='viridis', cbar=False, yticklabels=False)\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Dataset Overview**:\n",
        "   - The dataset contains information about Yes Bank's stock prices.\n",
        "   - It comprises 185 entries (rows) and 5 columns.\n",
        "   - Each row represents monthly stock data, including the date, opening price, highest price, lowest price, and closing price.\n",
        "\n",
        "2. **Duplicate Values**:\n",
        "   - There are no duplicate rows present in the dataset, indicating that each entry is unique.\n",
        "\n",
        "3. **Missing Values**:\n",
        "   - There are no missing or null values present in any of the columns.\n",
        "\n",
        "In summary, the dataset consists of complete and unique monthly stock price data for Yes Bank, including information on opening, highest, lowest, and closing prices. There are no issues with duplicates or missing values, making the dataset suitable for analysis and modeling."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "dataset_columns = data.columns\n",
        "\n",
        "print(\"Dataset Columns:\")\n",
        "dataset_columns\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "dataset_description = data.describe()\n",
        "\n",
        "print(\"Dataset Descriptive Statistics:\")\n",
        "print(dataset_description)\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The dataset consists of five columns:\n",
        "\n",
        "1. **Date**: This column represents the date of the stock data entry.\n",
        "2. **Open**: This column indicates the opening price of Yes Bank's stock for each respective date.\n",
        "3. **High**: This column displays the highest price reached by Yes Bank's stock during the respective date.\n",
        "4. **Low**: This column shows the lowest price recorded for Yes Bank's stock on the given date.\n",
        "5. **Close**: This column denotes the closing price of Yes Bank's stock for each specific date.\n",
        "\n",
        "Descriptive statistics provide insights into the distribution and central tendencies of the numerical columns:\n",
        "\n",
        "- **Open**: The average opening price is approximately 105.54, with prices ranging from a minimum of 10 to a maximum of 369.95.\n",
        "- **High**: The average highest price is around 116.10, with values varying between 11.24 (minimum) and 404.00 (maximum).\n",
        "- **Low**: The average lowest price stands at about 94.95, with the lowest and highest values being 5.55 and 345.50, respectively.\n",
        "- **Close**: The average closing price is roughly 105.20. The closing prices vary between a minimum of 9.98 and a maximum of 367.90.\n",
        "\n",
        "These descriptive statistics provide a comprehensive overview of the Yes Bank stock prices' distribution and variability over the dataset's timeframe."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "unique_values_count = data.nunique()\n",
        "\n",
        "print(\"Total number of unique values for each variable:\")\n",
        "print(unique_values_count)\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Date' column to datetime format\n",
        "data['Date'] = pd.to_datetime(data['Date'], format='%b-%y')\n",
        "\n",
        "# Format dates to include full year with shortened month name\n",
        "data['Date'] = data['Date'].dt.strftime('%b-%Y')\n",
        "\n",
        "# Convert 'Date' column back to datetime datatype\n",
        "data['Date'] = pd.to_datetime(data['Date'], format='%b-%Y')\n",
        "\n",
        "# Check the updated data types and first few rows\n",
        "print('Data type of \\'Date\\' column:', data['Date'].dtype)\n",
        "print(data['Date'].head())"
      ],
      "metadata": {
        "id": "FlmPPfVZtT6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 'Month' column to store short month names\n",
        "data['Month'] = data['Date'].dt.strftime('%b')\n",
        "\n",
        "# Display the first few rows of the updated DataFrame\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "sjVIdvDUJTQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* First, we change the 'Date' column's datatype to \"Datetime\". Then, we create a new column named 'Month' where we store the month names in string format."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 - Yes Bank's Yearly Average Stock Closing Prices"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1. visualization code\n",
        "\n",
        "# Extract year from 'Date' column\n",
        "data['Year'] = data['Date'].dt.year\n",
        "\n",
        "# Group data by 'Year' and calculate average closing price\n",
        "yearly_data = data.groupby('Year')['Close'].mean().reset_index()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.plot(yearly_data['Year'], yearly_data['Close'], marker='o', linestyle='-')\n",
        "plt.title('Yearly Average Closing Stock Prices')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average Closing Price')\n",
        "plt.grid(True)\n",
        "\n",
        "# Set x-axis ticks to display all years from 2005\n",
        "plt.xticks(yearly_data['Year'])  # Set x-axis ticks to yearly_data['Year']\n",
        "\n",
        "# Annotate each data point\n",
        "for i, txt in enumerate(yearly_data['Close']):\n",
        "    plt.annotate(f\"{txt:.2f}\", (yearly_data['Year'].iloc[i], yearly_data['Close'].iloc[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The specific chart, a line plot of yearly average closing stock prices, was chosen because it effectively visualizes the annual trends in stock performance. This chart allows for easy identification of patterns, such as increases or decreases in average stock prices over the years. Additionally, annotating each data point with the average closing price provides specific information at a glance, making it easier to understand and interpret the yearly stock price trends for the given dataset."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From the above line chart, we can clearly see that after the listing of Yes Bank's stocks in the stock market in 2005, its stock price increased consistently with some ups and downs. The first significant price drop occurred in 2008 when the average price was ₹28.25. The price saw a minimalistic increase in 2009, reaching ₹30.03. However, it fell again in 2011 to ₹57.22 from an average of ₹58.65 in 2010.\n",
        "\n",
        " From 2011 onwards, the stock price began to rise steadily, reaching its all-time high average price of ₹315.31 in 2017. However, after 2017, the price dropped drastically, closing at an average of ₹22.11 in 2020. This sharp decline was primarily due to the 2018 scam involving Yes Bank."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* **Positive Business Impact:**\n",
        "Understanding the consistent growth of Yes Bank's stock price from 2005 to 2017 can instill confidence among investors about the bank's potential for growth and profitability. It shows that, despite some fluctuations, the bank has the capability to recover and reach new heights.\n",
        "\n",
        "* **Negative Growth Insights:**\n",
        "The drastic drop in the stock price after 2017, especially the sharp decline to ₹22.11 in 2020, raises concerns. This significant decrease is directly linked to the 2018 scam involving Yes Bank. Such negative events can erode investor trust and confidence in the bank's management and operations, potentially leading to reduced investments and a decline in the bank's market value.\n",
        "\n",
        " In summary, while the historical data indicates periods of growth and stability for Yes Bank, the recent decline underscores the importance of addressing and mitigating the impact of negative events, like scams, to maintain investor trust and ensure sustained business growth."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 - Yes Bank's Stock Price Movements by Year and Month"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2. visualization code\n",
        "\n",
        "# Create a combined Candlestick chart for all years\n",
        "fig = go.Figure(go.Candlestick(x=data['Date'],\n",
        "                open=data['Open'],\n",
        "                high=data['High'],\n",
        "                low=data['Low'],\n",
        "                close=data['Close']))\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(title={'text': 'Yes Bank\\'s Stock Price Movements by Year and Month', 'x': 0.5, 'y': 0.95},\n",
        "                  xaxis_title='Date',\n",
        "                  yaxis_title='Price',\n",
        "                  width=1380,\n",
        "                  height=930,\n",
        "                  plot_bgcolor='rgb(240, 240, 240)',\n",
        "                  paper_bgcolor='rgb(240, 240, 240)'\n",
        ")\n",
        "\n",
        "# Show plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "ZM33CqwIfYmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The specific chart, a combined Candlestick chart, was chosen to visualize the stock price movements of Yes Bank over multiple years. This type of chart efficiently displays the open, high, low, and close prices of the stock, allowing for a comprehensive understanding of price fluctuations and trends over time."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When Yes Bank was listed in the share market in July 2005, their stock prices were:\n",
        "\n",
        "Open: ₹13  \n",
        "High: ₹14  \n",
        "Low: ₹11.25  \n",
        "Close: ₹12.46  \n",
        "\n",
        "These prices increased consistently until January 2008, reaching:\n",
        "\n",
        "Open: ₹49.99  \n",
        "High: ₹55.56  \n",
        "Low: ₹30.24  \n",
        "Close: ₹50.54  \n",
        "\n",
        "This marked the first and highest positive increase in stock prices. After this, there were fluctuations in stock prices, but the last significant positive increase was observed in July 2018, with:\n",
        "\n",
        "Open: ₹340  \n",
        "High: ₹393.35  \n",
        "Low: ₹332.45  \n",
        "Close: ₹367.9  \n",
        "\n",
        "However, after this peak in 2018, Yes Bank's stock prices began to decline steadily due to the 2018 Yes Bank scam."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* **Positive Impact:**  \n",
        "Yes, the data reveals that Yes Bank's stock had significant positive growth from its listing in 2005 to January 2008 and another notable increase in July 2018. Understanding these growth periods can help businesses identify factors or strategies that contributed to this growth, potentially replicating them for positive business impact.\n",
        "\n",
        "* **Negative Impact:**  \n",
        "The data also highlights a decline in Yes Bank's stock prices after the 2018 peak, attributed to the 2018 Yes Bank scam. This decline can serve as a cautionary insight for businesses, emphasizing the importance of maintaining transparency, trust, and ethical practices to sustain stock prices and avoid negative growth."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 - Distribution of stock prices with their frequency of each variable"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "\n",
        "variables = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "# Define colors for each variable\n",
        "colors = ['blue', 'green', 'red', 'purple']\n",
        "\n",
        "# Set the figure size and style\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Iterate through each variable to plot histogram and KDE\n",
        "for var, color in zip(variables, colors):\n",
        "    plt.subplot(2, 2, variables.index(var) + 1)\n",
        "    sns.histplot(data[var], kde=True, bins=30, color=color, edgecolor='black')\n",
        "    plt.title(f'Distribution of {var} Stock Prices')\n",
        "    plt.xlabel(f'{var} Stock Price (₹)')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The specific chart was chosen to visualize the distribution of different stock price variables (Open, High, Low, Close) using histograms and Kernel Density Estimation (KDE). This allows for a clear comparison of the frequency distribution of each variable, helping to understand their overall patterns and variability."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The distribution of stock prices for each variable shows similarities. Most stocks have a similar number of prices ranging between 0 to 100 in the variables Open, High, Low, and Close. From this, we can conclude that the majority of stocks are skewed towards or lie within the price range of 0 to 100 Rs."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The gained insights about the positively skewed distributions of open, high, low, and close prices can have a positive business impact by informing strategic decision-making and identifying potential buying opportunities. However, it is important to note that positive skewness does not directly imply negative growth. Negative growth would require a comprehensive analysis considering various factors beyond skewness, such as trends, market conditions, and external influences. Therefore, it is not justified to conclude specific insights leading to negative growth based solely on the skewness of the distributions. Further analysis is needed to assess any potential negative impacts on business growth."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 - Identifying outliers"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "# Define the variables to visualize\n",
        "variables = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "# Set the figure size and style\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create boxplot for each variable\n",
        "sns.boxplot(data=data[variables], palette=\"Set2\")\n",
        "plt.title('Boxplot of Stock Prices')\n",
        "plt.ylabel('Price (₹)')\n",
        "plt.xlabel('Variables')\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The specific chart chosen here is a boxplot. A boxplot is selected because it provides a concise visual summary of the distribution of numerical data across multiple variables. It allows us to quickly compare the distribution of stock prices (open, high, low, close) in a single plot. The boxplot shows the median, quartiles, and any outliers present in the data, making it easy to identify any variability or skewness in the stock price data across different variables. Overall, it offers a clear and compact representation of the central tendency and spread of the stock prices, aiding in effective data exploration and analysis."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we can see in the above chart, there are some larger values considered as outliers in the dataset. However, we can't remove them because they are important for our analysis."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The insights gained from identifying outliers can indeed help create a positive business impact. By understanding the presence and significance of these outliers, businesses can make more informed decisions and develop strategies that account for extreme values in their data. This can lead to better risk management, improved forecasting accuracy, and enhanced understanding of market trends.\n",
        "\n",
        " However, the presence of outliers may also indicate potential areas of concern or negative growth. For example, if outliers represent unusually high or low sales figures, they could indicate irregularities in sales patterns or the presence of anomalies that require further investigation. Addressing these insights appropriately can help mitigate risks and ensure the overall health and stability of the business."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 - Correlation between the bivariate variables"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "numeric_data = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = numeric_data.corr()\n",
        "\n",
        "# Function to create scatter plot for a single variable against 'Close'\n",
        "def create_scatter_plot(var, df):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Create scatter plot\n",
        "    sns.scatterplot(x=var, y='Close', data=df, label=f'{var} vs Close', alpha=0.7)\n",
        "\n",
        "    plt.xlabel(var)\n",
        "    plt.ylabel('Close')\n",
        "    plt.title(f\"{var} Vs. Close\", fontsize=16)\n",
        "\n",
        "    # Fit a linear regression line to the data\n",
        "    z = np.polyfit(df[var], df['Close'], 1)\n",
        "    y_hat = np.poly1d(z)(df[var])\n",
        "\n",
        "    plt.plot(df[var], y_hat, \"r\", lw=1)\n",
        "\n",
        "    # Add grid lines with transparency\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.xticks(np.arange(min(df[var]), max(df[var]), 100))\n",
        "    plt.yticks(np.arange(min(df['Close']), max(df['Close']), 10))\n",
        "\n",
        "    # Display correlation score at the middle top of the chart\n",
        "    correlation = df[var].corr(df['Close'])\n",
        "    plt.text(0.5, 0.95, f'Correlation: {round(correlation, 2)}', transform=plt.gca().transAxes, fontsize=12,\n",
        "             verticalalignment='center', horizontalalignment='center', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Create scatter plots for each variable\n",
        "variables = ['Open', 'High', 'Low']\n",
        "\n",
        "for var in variables:\n",
        "    create_scatter_plot(var, data)"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The scatter plots were chosen to visually show the relationship between each stock price metric ('Open', 'High', 'Low') and the closing price ('Close'). By plotting these variables against each other, we can easily see how changes in one metric might be associated with changes in the closing price. The added regression line and correlation score help to highlight the strength and direction of this relationship."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* After reviewing the scatter plots with the best fit line, it's clear that all the independent variables—Open, High, and Low—exhibit a linear relationship with the dependent variable, Close. This means that when Open, High, or Low values change, the Close price tends to change proportionally in a predictable manner.\n",
        "\n",
        " This discovery is crucial for data analysis and modeling. It implies that we can use the values of Open, High, and Low to make predictions about the Close price accurately. Understanding this relationship helps us build reliable models and gain insights into how changes in these variables affect the Close price."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Identifying linear relationships between independent variables like Open, High, and Low, and the dependent variable Close in stock market analysis has big business impacts:\n",
        "\n",
        "1. **Better Predictions**: We can use these relationships to predict future Close prices, helping investors make smarter investment choices.\n",
        "\n",
        "2. **Understanding Risk**: Knowing how changes in these variables affect Close prices helps assess and manage investment risks effectively.\n",
        "\n",
        "3. **Choosing Key Factors**: By spotting which variables influence Close prices the most, we can focus on them for better analysis and decision-making.\n",
        "\n",
        "4. **Developing Strategies**: Understanding these relationships can lead to creating trading strategies, spotting trends, and making more informed investment moves.\n",
        "\n",
        " Overall, recognizing and grasping these linear relationships gives businesses and investors valuable insights into stock price dynamics, leading to better forecasting, risk management, and decision-making in financial markets."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "numeric_data = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = numeric_data.corr()\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create the heatmap\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt=\".2f\", linewidths=.5)\n",
        "\n",
        "# Add title\n",
        "plt.title('Correlation Heatmap')\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The heatmap was chosen because it's an effective way to visualize correlations between different variables in a dataset. With colors representing correlation values, it's easy to spot which variables are positively or negatively related to each other. This helps in understanding how changes in one variable might affect another, providing valuable insights for analysis and decision-making."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From the heatmap, we can see that variables like 'Open', 'High', and 'Low' have a strong correlation with the 'Close' variable, with values of 0.98, 0.99, and 1 respectively. This indicates that a small change in these variables will also significantly affect the 'Close' variable. On the other hand, the 'Year' variable doesn't show a strong correlation with these variables, having a correlation of around 0.6. This suggests that changes in these price variables won't greatly impact the 'Year', and vice versa."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "\n",
        "# Selecting relevant columns for the pair plot\n",
        "selected_columns = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "# Create pair plot\n",
        "sns.pairplot(data[selected_columns])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The pair plot is chosen because it provides a quick visual overview of the relationships between multiple pairs of variables. By plotting all selected columns against each other, we can easily spot patterns, trends, and correlations between the stock prices (Open, High, Low, Close). This helps in understanding how these variables relate to one another and if there are any evident relationships or patterns between them."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The opening, highest, and lowest prices of the stock show a strong connection with its closing price. This means that when one of these prices goes up or down, it often affects the closing price in a similar way. Also, these three prices are closely related to each other, indicating they tend to move together and follow similar patterns.\n",
        "\n",
        " These relationships give us useful insights into understanding how Yes Bank's stock behaves. They can help us predict what the closing price might be based on the opening, highest, and lowest prices. Knowing these connections helps us make better decisions and spot trends for predicting future stock prices. However, it's essential to remember that just because two things are correlated doesn't mean one causes the other. So, it's crucial to consider other factors too when analyzing the stock market."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we can see, our dataset has no missing values. Therefore, we don't need any kind of missing value treatment technique."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# Apply log transformation to 'Open', 'High', 'Low', 'Close' columns\n",
        "for col in ['Open', 'High', 'Low', 'Close']:\n",
        "    data[col] = np.log1p(data[col])\n",
        "\n",
        "# Set the style for the seaborn library\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Define colors for each variable\n",
        "colors = ['blue', 'green', 'red', 'purple']\n",
        "\n",
        "# Visualize the transformed data distribution using boxplots\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, col in enumerate(['Open', 'High', 'Low', 'Close'], 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.boxplot(data[col], color=colors[i-1], width=0.3)\n",
        "    plt.title(f'Boxplot of {col} (After Log Transformation)')\n",
        "    plt.xlabel(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Our dataset contains some larger values that can't be removed because they are important data points in our dataset. Therefore, we use log transformation to handle the outliers. After this transformation, we create a boxplot to show that no outliers remain outside the whiskers."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Our dataset only has numerical data, so we don't need to worry about converting categorical variables into numbers for analysis or modeling."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = ['Open', 'High', 'Low','Close']\n",
        "data_numerical = data[numerical_cols]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "data_numerical_scaled = scaler.fit_transform(data_numerical)\n",
        "\n",
        "# Create an empty dataframe to store the VIF for each feature\n",
        "vif_df = pd.DataFrame()\n",
        "\n",
        "# Assign the feature names to the 'Features' column\n",
        "vif_df['Features'] = numerical_cols\n",
        "\n",
        "# Calculate the VIF for each feature and store it in the 'VIF' column\n",
        "vif_df['VIF'] = [variance_inflation_factor(data_numerical_scaled, i) for i in range(len(data_numerical.columns))]\n",
        "\n",
        "# Display the dataframe containing the features and their corresponding VIF values\n",
        "print(vif_df)\n"
      ],
      "metadata": {
        "id": "7znin6yjm-Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The VIF values for all the features suggest strong multicollinearity. However, since our dataset is small and contains only four numerical independent variables, there's limited room for beneficial feature manipulation. Additionally, without categorical variables, our options for feature engineering or transformation are limited. Therefore, we should focus on exploring alternative modeling approaches or collecting more data to mitigate the issue of multicollinearity."
      ],
      "metadata": {
        "id": "fa9Vi5JipXPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here, we didn't use any feature selection methods because our dataset is already small, containing a limited number of variables. Therefore, we used all these variables as they are, considering them as our features."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In our analysis, all features (Open, High, Low, Close) were considered important because they represent key metrics of stock prices. Each feature provides valuable information about the stock's performance, such as the opening price, highest price, lowest price, and closing price for a given period. These features collectively contribute to understanding the overall trend and behavior of the stock market, making them essential for analysis and modeling."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "\n",
        "# Apply log transformation to the numerical columns\n",
        "data_log_transformed = np.log1p(data[numerical_cols])\n",
        "\n",
        "# Visualize the transformed data distributions\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Define dark colors\n",
        "dark_colors = ['darkblue', 'darkgreen', 'darkred', 'darkorange']\n",
        "\n",
        "for i, col in enumerate(numerical_cols, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.histplot(data_log_transformed[col], bins=20, kde=True, color=dark_colors[i - 1])\n",
        "    plt.title(f'Distribution of {col} (After Log Transformation)')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TEdlxyhyuDKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Yes, the data needed to be transformed. We applied a log transformation to the numerical columns (Open, High, Low, Close).\n",
        "\n",
        " **Log Transformation Definition:**  \n",
        "Log transformation is a mathematical operation that applies the natural logarithm function to each data point. It is used to stabilize the variance across the data, make skewed data more symmetric, and reduce the impact of outliers.\n",
        "\n",
        " **Why we used log transformation:**\n",
        "- Log transformation helps to stabilize the variance across the data and reduce the impact of outliers.\n",
        "- It makes the data more symmetric and conform closer to a normal distribution, which can improve the performance of certain statistical and machine learning models.\n",
        "- Log transformation also ensures that small changes in the original data correspond to similar changes in the transformed data, which can be beneficial in certain analysis scenarios.\n",
        "\n",
        "Overall, log transformation helped to address potential issues like skewed distributions and variability in the data, making it more suitable for analysis and modeling purposes."
      ],
      "metadata": {
        "id": "BTgSR9LVvbTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the numerical data\n",
        "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "\n",
        "# Display the first few rows of the scaled data\n",
        "print(data[numerical_cols].head())"
      ],
      "metadata": {
        "id": "WbwgL0Msw-td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Standard Scaler Definition:**  \n",
        "StandardScaler is a method used for standardizing features by removing the mean and scaling to unit variance. This means it transforms the data so that it has a mean of 0 and a standard deviation of 1.\n",
        "\n",
        " **Why We Used Standard Scaler:**  \n",
        "We used StandardScaler to bring all the numerical features (Open, High, Low, Close) to a similar scale. This helps in ensuring that all features contribute equally to the model training and prevents features with larger scales from dominating the learning process. Standardizing the data also improves the performance of certain machine learning algorithms and helps in achieving faster convergence during model training."
      ],
      "metadata": {
        "id": "4sXU-lIGx3UT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we know, our dataset is not very large and has a limited number of variables. Therefore, we don't need any kind of dimensionality reduction here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "# Define independent and dependent variables\n",
        "independent_variables = ['Open', 'High', 'Low']\n",
        "dependent_variable = 'Close'\n",
        "\n",
        "# Assign the independent and dependent variables to X and y, respectively\n",
        "X = data[independent_variables]\n",
        "y = data[dependent_variable]\n",
        "\n",
        "# Split the data into training and testing datasets using a test size of 0.2 (20%)\n",
        "# Set random_state to 0 for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Display the shape of the train and test sets\n",
        "print(\"X_train:\\n\", X_train.head())\n",
        "print(\"\\nX_test:\\n\", X_test.head())\n",
        "print(\"\\ny_train:\\n\", y_train.head())\n",
        "print(\"\\ny_test:\\n\", y_test.head())\n"
      ],
      "metadata": {
        "id": "AvYg7ltn3-at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a data splitting ratio of 80:20, meaning 80% of the data is used for training the model and 20% for testing.\n",
        "\n",
        "**Reason for the 80:20 Ratio:**  \n",
        "We chose this ratio because it strikes a balance between having enough data for training the model effectively and having enough data for testing to evaluate the model's performance accurately. This ratio helps prevent overfitting while ensuring that the model has sufficient data to learn patterns and relationships from the training set. Additionally, a larger training set often leads to more robust and generalizable models, which is why we allocated the majority of the data (80%) for training purposes."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There is no need to balance the dataset."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 - Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data. In simpler terms, it helps us understand how the value of the dependent variable changes with the change in one or more independent variables. The goal is to find the best-fitting straight line (or hyperplane in higher dimensions) that predicts the dependent variable based on the independent variable(s)."
      ],
      "metadata": {
        "id": "XsQw9qThzZEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Linear Regression Implementation :-\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the Algorithm :-\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model :-\n",
        "\n",
        "# Predict on the training and testing data\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "# Calculate R-squared score\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Training MAE: \", train_mae)\n",
        "print(\"Testing MAE: \", test_mae)\n",
        "print(\"\\nTraining MSE: \", train_mse)\n",
        "print(\"Testing MSE: \", test_mse)\n",
        "print(\"\\nTraining R-squared: \", train_r2)\n",
        "print(\"Testing R-squared: \", test_r2)\n",
        "\n",
        "# Print the predicted values\n",
        "print(\"\\nPredicted values for y_test:\\n\", y_test_pred)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "# Evaluation metric names\n",
        "metrics = ['MAE', 'MSE', 'R-squared']\n",
        "training_scores = [train_mae, train_mse, train_r2]\n",
        "testing_scores = [test_mae, test_mse, test_r2]\n",
        "\n",
        "# Number of metrics\n",
        "num_metrics = len(metrics)\n",
        "\n",
        "# Set width of bar\n",
        "bar_width = 0.35\n",
        "\n",
        "# Set position of bar on X axis\n",
        "r1 = np.arange(num_metrics)\n",
        "r2 = [x + bar_width for x in r1]\n",
        "\n",
        "# Create bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars1 = plt.bar(r1, training_scores, color='blue', width=bar_width, edgecolor='grey', label='Training')\n",
        "bars2 = plt.bar(r2, testing_scores, color='orange', width=bar_width, edgecolor='grey', label='Testing')\n",
        "\n",
        "# Add annotations to the bars\n",
        "for bar in bars1:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.001, round(yval, 4), ha='center', va='bottom')\n",
        "\n",
        "for bar in bars2:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.001, round(yval, 4), ha='center', va='bottom')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Metrics', fontweight='bold')\n",
        "plt.ylabel('Score', fontweight='bold')\n",
        "plt.xticks([r + bar_width/2 for r in range(num_metrics)], metrics)\n",
        "plt.title('Evaluation Metric Scores Comparison (Training vs Testing)')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "H8KVZxnms6nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the actual Close prices from the test data\n",
        "plt.plot(y_test.values, color='blue')\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "lr_grid_pred = model.predict(X_test)\n",
        "\n",
        "# Plot the predicted Close prices from the Linear Regression model\n",
        "plt.plot(lr_grid_pred, color='red')\n",
        "\n",
        "# Set the label for the y-axis\n",
        "plt.ylabel(\"Close Price\")\n",
        "\n",
        "# Add a legend to differentiate between the actual and predicted values\n",
        "plt.legend([\"Actual\", \"Predicted\"])\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Linear Regression\")\n",
        "\n",
        "# Add gridlines\n",
        "plt.grid(which='major', alpha=0.5)\n",
        "plt.grid(which='minor', alpha=0.5)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RF_qMaRt2eFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.) :-\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'positive': [True, False],\n",
        "    'copy_X': [True, False]\n",
        "}\n",
        "\n",
        "# Instantiate the GridSearchCV object\n",
        "lr_grid = GridSearchCV(LinearRegression(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the Algorithm :-\n",
        "\n",
        "# Fit the grid search to the data\n",
        "lr_grid.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and its parameters\n",
        "best_lr = lr_grid.best_estimator_\n",
        "best_params = lr_grid.best_params_\n",
        "\n",
        "# Predict on the model :-\n",
        "\n",
        "# Predict using the best model\n",
        "lr_grid_pred = best_lr.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the best model\n",
        "lr_grid_mae = mean_absolute_error(y_test, lr_grid_pred)\n",
        "lr_grid_mse = mean_squared_error(y_test, lr_grid_pred)\n",
        "lr_grid_r2 = r2_score(y_test, lr_grid_pred)\n",
        "\n",
        "# Print the mean squared error for the best model\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Mean Absolute Error (GridSearchCV):\", lr_grid_mae)\n",
        "print(f\"Linear Regression MSE (GridSearchCV): {lr_grid_mse}\")\n",
        "print(f\"Linear Regression R2 Score (GridSearchCV): {lr_grid_r2}\")\n"
      ],
      "metadata": {
        "id": "jsUbNe6401N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I used GridSearchCV for hyperparameter optimization. GridSearchCV systematically tests all combinations of hyperparameters from a specified grid to find the best model. It's a reliable method to find the optimal hyperparameters for a model based on the provided scoring metric."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there is a slight improvement in the evaluation metric scores after implementing hyperparameter optimization techniques (GridSearchCV) for the Linear Regression model:\n",
        "\n",
        "Before:\n",
        "- Training MAE: 0.0489\n",
        "- Testing MAE: 0.0408\n",
        "- Training MSE: 0.0049\n",
        "- Testing MSE: 0.0047\n",
        "- Training R-squared: 0.9950\n",
        "- Testing R-squared: 0.9954\n",
        "\n",
        "After:\n",
        "- Training MAE: 0.0407\n",
        "- Testing MAE: 0.0407\n",
        "- Training MSE: 0.0047\n",
        "- Testing MSE: 0.0047\n",
        "- Training R-squared: 0.9955\n",
        "- Testing R-squared: 0.9955\n",
        "\n",
        "In summary, after hyperparameter optimization, we observed a reduction in mean absolute error (MAE) for both training and testing datasets, as well as a slight improvement in R-squared values, indicating better model performance."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 - Decision Tree"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A decision tree is a flowchart-like tree structure where an internal node represents a feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome. The topmost node in a tree is known as the root node. It learns to partition the data based on the features that lead to the most significant reduction in impurity (or uncertainty), typically using metrics like Gini impurity or information gain. Decision trees are versatile and can be used for both classification and regression tasks. They provide a clear visualization of the decision-making process and are relatively easy to understand and interpret."
      ],
      "metadata": {
        "id": "oH64mUPt-bjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Decision Tree Implementation :-\n",
        "\n",
        "# Initialize the Decision Tree Regressor model\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Fit the Algorithm :-\n",
        "\n",
        "# Fit the model to the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model :-\n",
        "\n",
        "# Predict on the training data\n",
        "dt_train_pred = dt.predict(X_train)\n",
        "\n",
        "# Evaluate the performance of the model on training data\n",
        "dt_train_mse = mean_squared_error(y_train, dt_train_pred)\n",
        "dt_train_mae = mean_absolute_error(y_train, dt_train_pred)\n",
        "dt_train_r2 = r2_score(y_train, dt_train_pred)\n",
        "\n",
        "# Print the mean squared error, mean absolute error, and R-squared score for training data\n",
        "print(f\"Decision Tree Regressor Training MSE: {dt_train_mse}\")\n",
        "print(f\"Decision Tree Regressor Training MAE: {dt_train_mae}\")\n",
        "print(f\"Decision Tree Regressor Training R2 Score: {dt_train_r2}\")\n",
        "print(f\"Predicted Values for Training Data: {dt_train_pred}\")\n",
        "\n",
        "# Predict on the testing data\n",
        "dt_test_pred = dt.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model on testing data\n",
        "dt_test_mse = mean_squared_error(y_test, dt_test_pred)\n",
        "dt_test_mae = mean_absolute_error(y_test, dt_test_pred)\n",
        "dt_test_r2 = r2_score(y_test, dt_test_pred)\n",
        "\n",
        "# Print the mean squared error, mean absolute error, and R-squared score for testing data\n",
        "print(f\"\\nDecision Tree Regressor Testing MSE: {dt_test_mse}\")\n",
        "print(f\"Decision Tree Regressor Testing MAE: {dt_test_mae}\")\n",
        "print(f\"Decision Tree Regressor Testing R2 Score: {dt_test_r2}\")\n",
        "print(f\"Predicted Values for Testing Data: {dt_test_pred}\")\n"
      ],
      "metadata": {
        "id": "Xl8iwIrrBWRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "# Evaluation metric names\n",
        "metrics = ['MSE', 'MAE', 'R2 Score']\n",
        "training_scores = [dt_train_mse, dt_train_mae, dt_train_r2]\n",
        "testing_scores = [dt_test_mse, dt_test_mae, dt_test_r2]\n",
        "\n",
        "# Number of metrics\n",
        "num_metrics = len(metrics)\n",
        "\n",
        "# Set width of bar\n",
        "bar_width = 0.35\n",
        "\n",
        "# Set position of bar on X axis\n",
        "r1 = np.arange(num_metrics)\n",
        "r2 = [x + bar_width for x in r1]\n",
        "\n",
        "# Create bar chart\n",
        "plt.figure(figsize=(12, 8))\n",
        "bars1 = plt.bar(r1, training_scores, color='blue', width=bar_width, edgecolor='grey', label='Training')\n",
        "bars2 = plt.bar(r2, testing_scores, color='orange', width=bar_width, edgecolor='grey', label='Testing')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Metrics', fontweight='bold')\n",
        "plt.ylabel('Score', fontweight='bold')\n",
        "plt.xticks([r + bar_width/2 for r in range(num_metrics)], metrics)\n",
        "plt.title('Decision Tree Regressor Evaluation Metric Scores Comparison (Training vs Testing)')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Add annotations on top of the bars\n",
        "for bar, score in zip(bars1, training_scores):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{score:.4f}',\n",
        "             ha='center', va='bottom', color='white')\n",
        "\n",
        "for bar, score in zip(bars2, testing_scores):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{score:.4f}',\n",
        "             ha='center', va='bottom', color='black')\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cc6l8kx-7bAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Decision Tree Regressor model\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing data\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "# Plotting actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Scatter plot for actual values\n",
        "plt.scatter(y_test, y_test, color='green', label='Actual', alpha=0.6)\n",
        "\n",
        "# Scatter plot for predicted values\n",
        "plt.scatter(y_test, dt_pred, color='blue', label='Predicted', alpha=0.6)\n",
        "\n",
        "# Adding a line connecting actual and predicted values\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, color='red', label='Perfect Prediction Line')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values (Decision Tree)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uS9YCORM_3Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2. Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.) :-\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Initialize the Decision Tree Regressor\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Instantiate the GridSearchCV object\n",
        "dt_grid = GridSearchCV(dt, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the Algorithm :-\n",
        "\n",
        "# Fit the grid search to the data\n",
        "dt_grid.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and its parameters\n",
        "best_dt = dt_grid.best_estimator_\n",
        "best_params = dt_grid.best_params_\n",
        "\n",
        "# Predict on the model :-\n",
        "\n",
        "# Predict using the best model\n",
        "dt_grid_pred = best_dt.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the best model\n",
        "dt_grid_mse = mean_squared_error(y_test, dt_grid_pred)\n",
        "dt_grid_mae = mean_absolute_error(y_test, dt_grid_pred)\n",
        "dt_grid_r2 = r2_score(y_test, dt_grid_pred)\n",
        "\n",
        "# Print the mean squared error, mean absolute error, and R-squared score for the best model\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(f\"Decision Tree Regressor MSE (GridSearchCV): {dt_grid_mse}\")\n",
        "print(f\"Decision Tree Regressor MAE (GridSearchCV): {dt_grid_mae}\")\n",
        "print(f\"Decision Tree Regressor R2 Score (GridSearchCV): {dt_grid_r2}\")\n"
      ],
      "metadata": {
        "id": "kgS0ZKpbCz4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hyperparameter optimization technique  I used here is GridSearchCV.\n",
        "\n",
        "**Why GridSearchCV?**\n",
        "\n",
        "GridSearchCV is used because it systematically tests all combinations of hyperparameters from the specified grid to find the best set of hyperparameters for the Decision Tree Regressor. This method ensures that we are not missing out on any potential good combinations and helps in identifying the optimal hyperparameters for our model based on the specified scoring metric (in this case, 'neg_mean_squared_error')."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there has been a slight improvement in the performance of the Decision Tree Regressor after hyperparameter tuning using GridSearchCV.\n",
        "\n",
        "**Improvement:**\n",
        "- **MSE:** The mean squared error decreased from 0.0241 to 0.0233, indicating that the model's predictions are closer to the actual values on average after hyperparameter tuning.\n",
        "- **MAE:** The mean absolute error decreased from 0.0867 to 0.0808, showing that the average difference between predicted and actual values reduced.\n",
        "- **R2 Score:** The R2 score increased from 0.9766 to 0.9774, indicating that the model explains a slightly higher percentage of the variance in the target variable after hyperparameter tuning.\n",
        "\n",
        "Overall, these improvements suggest that the tuned model performs slightly better in terms of prediction accuracy and model fit compared to the model before hyperparameter tuning."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Mean Squared Error (MSE):**\n",
        "\n",
        " **Indication:** MSE measures the average squared difference between the predicted values and the actual values. A lower MSE indicates that the model's predictions are closer to the actual values on average.\n",
        "\n",
        " **Business Impact:** Lower MSE means the model is making more accurate predictions, which can lead to better decision-making in business processes. For example, in financial forecasting, a lower MSE can help in more accurate budgeting and resource allocation.\n",
        "\n",
        "* **Mean Absolute Error (MAE):**\n",
        "\n",
        " **Indication:** MAE measures the average absolute difference between the predicted values and the actual values. Similar to MSE, a lower MAE indicates that the model's predictions are closer to the actual values.\n",
        "\n",
        " **Business Impact:** Lower MAE signifies better accuracy in predictions, which can result in improved operational efficiency. For instance, in inventory management, lower MAE means better forecasting of demand, reducing the risk of overstocking or stockouts.\n",
        "\n",
        "* **R-squared (R2) Score:**\n",
        "\n",
        " **Indication:** R2 score measures the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, where 1 indicates a perfect fit.\n",
        "\n",
        " **Business Impact:** A higher R2 score indicates that the model explains a larger proportion of the variance in the target variable. This implies that the model's predictions align well with the actual data, which boosts confidence in decision-making. For example, in sales forecasting, a higher R2 score can lead to more reliable predictions of future sales, aiding in strategic planning and resource allocation.\n"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 - Random Forest"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Random Forest is a machine learning algorithm that builds multiple decision trees and combines their predictions to make a final prediction. It's like asking many experts (trees) their opinions and then deciding based on the most popular answer. This method often gives more accurate and robust predictions compared to using a single decision tree."
      ],
      "metadata": {
        "id": "pFIN-2P_pEQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Random Forest Implementation :-\n",
        "\n",
        "# Initialize the Random Forest Regressor model\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Fit the Algorithm :-\n",
        "\n",
        "# Fit the model to the training data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model:-\n",
        "\n",
        "# Before training\n",
        "# Predict on the testing data before training\n",
        "rf_pred_before = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model before training\n",
        "rf_mse_before = mean_squared_error(y_test, rf_pred_before)\n",
        "rf_mae_before = mean_absolute_error(y_test, rf_pred_before)\n",
        "rf_r2_before = r2_score(y_test, rf_pred_before)\n",
        "\n",
        "print(\"Metrics scores before training:\")\n",
        "print(f\"MSE: {rf_mse_before}\")\n",
        "print(f\"MAE: {rf_mae_before}\")\n",
        "print(f\"R2 Score: {rf_r2_before}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Fit the Algorithm :-\n",
        "\n",
        "# Fit the model to the training data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model:-\n",
        "\n",
        "# Predict on the testing data after training\n",
        "rf_pred_after = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model after training\n",
        "rf_mse_after = mean_squared_error(y_test, rf_pred_after)\n",
        "rf_mae_after = mean_absolute_error(y_test, rf_pred_after)\n",
        "rf_r2_after = r2_score(y_test, rf_pred_after)\n",
        "\n",
        "print(\"Metrics scores after training:\")\n",
        "print(f\"Random Forest Regressor MSE: {rf_mse_after}\")\n",
        "print(f\"Random Forest Regressor MAE: {rf_mae_after}\")\n",
        "print(f\"Random Forest Regressor R2 Score: {rf_r2_after}\")"
      ],
      "metadata": {
        "id": "lssqaJUdm30W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "# Evaluation metric names\n",
        "metrics = ['MSE', 'MAE', 'R2 Score']\n",
        "training_scores_before = [rf_mse_before, rf_mae_before, rf_r2_before]\n",
        "testing_scores_after = [rf_mse_after, rf_mae_after, rf_r2_after]\n",
        "\n",
        "# Number of metrics\n",
        "num_metrics = len(metrics)\n",
        "\n",
        "# Set width of bar\n",
        "bar_width = 0.35\n",
        "\n",
        "# Set position of bar on X axis\n",
        "r1 = np.arange(num_metrics)\n",
        "r2 = [x + bar_width for x in r1]\n",
        "\n",
        "# Create bar chart\n",
        "plt.figure(figsize=(14, 8))\n",
        "bars1 = plt.bar(r1, training_scores_before, color='blue', width=bar_width, edgecolor='grey', label='Before Tuning')\n",
        "bars2 = plt.bar(r2, testing_scores_after, color='orange', width=bar_width, edgecolor='grey', label='After Tuning')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Metrics', fontweight='bold')\n",
        "plt.ylabel('Score', fontweight='bold')\n",
        "plt.xticks([r + bar_width/2 for r in range(num_metrics)], metrics)\n",
        "plt.title('Random Forest Regressor Evaluation Metric Scores Comparison (Before vs After Tuning)')\n",
        "\n",
        "# Add annotations at the middle top of the bars\n",
        "for bar1, bar2, score1, score2 in zip(bars1, bars2, training_scores_before, testing_scores_after):\n",
        "    plt.text(bar1.get_x() + bar1.get_width() / 2, bar1.get_height() + 0.005, f'{score1:.4f}', ha='center', va='bottom', color='white')\n",
        "    plt.text(bar2.get_x() + bar2.get_width() / 2, bar2.get_height() + 0.005, f'{score2:.4f}', ha='center', va='bottom', color='black')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-yzFN07Rn5vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_test, color='blue', label='Actual', alpha=0.6)\n",
        "plt.scatter(y_test, rf_pred_after, color='green', label='Predicted', alpha=0.6)\n",
        "\n",
        "# Add a line for perfect predictions\n",
        "plt.plot(y_test, y_test, color='red', label='Perfect Prediction')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values (Random Forest)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rh8hUtU1oaep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.) :-\n",
        "\n",
        "# Initialize the Random Forest Regressor model\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Instantiate the GridSearchCV object\n",
        "rf_grid = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Fit the Algorithm :-\n",
        "\n",
        "# Fit the grid search to the data\n",
        "rf_grid.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and its parameters\n",
        "best_rf = rf_grid.best_estimator_\n",
        "best_params = rf_grid.best_params_\n",
        "\n",
        "# Predict on the model:-\n",
        "\n",
        "# Predict on the testing data\n",
        "rf_grid_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the best model\n",
        "rf_grid_mse = mean_squared_error(y_test, rf_grid_pred)\n",
        "rf_grid_mae = mean_absolute_error(y_test, rf_grid_pred)\n",
        "rf_grid_r2 = r2_score(y_test, rf_grid_pred)\n",
        "\n",
        "# Print the best parameters and the evaluation metrics\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(f\"Random Forest Regressor MSE (GridSearchCV): {rf_grid_mse}\")\n",
        "print(f\"Random Forest Regressor MAE (GridSearchCV): {rf_grid_mae}\")\n",
        "print(f\"Random Forest Regressor R2 Score (GridSearchCV): {rf_grid_r2}\")\n"
      ],
      "metadata": {
        "id": "AkpMoV2bq9mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hyperparameter optimization technique used here is GridSearchCV.\n",
        "\n",
        "GridSearchCV exhaustively searches through a specified hyperparameter grid to find the combination of hyperparameters that yields the best performance for the model. It evaluates each combination using cross-validation and selects the one with the highest score according to a specified evaluation metric, in this case, the negative mean squared error.\n",
        "\n",
        "GridSearchCV is a commonly used technique because it systematically explores the hyperparameter space, ensuring that the best combination is found within the specified search range. This helps in tuning the model to achieve better performance without the need for manual trial and error."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance of the Random Forest Regressor did not improve after hyperparameter tuning. In fact, there was a slight increase in the mean squared error (MSE) and mean absolute error (MAE) after tuning, indicating a slightly worse performance. However, the R-squared (R2) score remained almost the same, suggesting that the model's ability to explain the variance in the data did not change significantly. Overall, there was no substantial improvement in the model's performance after hyperparameter tuning."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a positive business impact, we primarily consider the mean squared error (MSE) and mean absolute error (MAE) metrics. These metrics indicate how close the predicted values are to the actual values. A lower MSE and MAE signify better accuracy, which is crucial for making reliable predictions in real-world applications. By minimizing these errors, we can enhance the model's precision and trustworthiness, leading to better decision-making and potentially higher profits for the business."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I chose **Linear Regression** as the final prediction model because it demonstrated the best performance based on key metrics such as Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared Score. Additionally, it provides a good balance between accuracy and simplicity, making it easier to interpret and implement in real-world scenarios."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Linear Regression**:\n",
        "   - **Model Explanation**: Linear regression assumes a linear relationship between the input features and the target variable. It tries to fit a straight line that best predicts the target based on the input features.\n",
        "   - **Feature Importance**: In linear regression, feature importance can be determined by the magnitude of the coefficients. A larger absolute value of a coefficient suggests a stronger influence of that feature on the target variable.\n",
        "\n",
        "2. **Decision Tree**:\n",
        "   - **Model Explanation**: A decision tree splits the data into subsets based on the features, creating a tree-like model of decisions. It makes decisions by asking a series of questions and learns to predict the target variable based on the answers.\n",
        "   - **Feature Importance**: Features that appear higher in the tree and are closer to the root are generally more important. The splitting criterion, such as Gini impurity or information gain, also provides insights into feature importance.\n",
        "\n",
        "3. **Random Forest**:\n",
        "   - **Model Explanation**: Random Forest is an ensemble of multiple decision trees. It creates several decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of individual trees as its prediction.\n",
        "   - **Feature Importance**: Random Forest calculates feature importance based on how much each feature decreases the impurity across all trees in the forest. The feature with the highest importance score is considered the most influential.\n",
        "\n",
        "For extracting feature importance in these models, libraries like `eli5`, `SHAP`, or `feature_importances_` attribute in scikit-learn can be used. These tools provide a clearer understanding of which features are most influential in making predictions."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, our project aimed to develop a predictive model for forecasting Yes Bank's stock prices. We explored various machine learning algorithms like Linear Regression, Decision Tree, and Random Forest, analyzing their performance before and after hyperparameter tuning. After thorough evaluation, we found that the Linear Regression model performed the best, providing the most accurate predictions. This model can be valuable for investors and stakeholders in making informed decisions about Yes Bank's stock investments. However, it's essential to continuously monitor and update the model to adapt to changing market conditions and improve its accuracy over time. Overall, our project demonstrates the potential of machine learning in predicting stock prices and supporting investment strategies."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}